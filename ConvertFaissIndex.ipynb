{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be28c254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss \n",
    "import numpy as np\n",
    "from faiss.loader import swig_ptr\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from faiss.contrib.inspect_tools import get_invlist\n",
    "#from run_inference import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9211fe",
   "metadata": {},
   "source": [
    "### Description \n",
    "\n",
    "This script contains the code to extract the data structures required by EMVB from a ```faiss``` index.\n",
    "\n",
    "It assumes you already trained a ```faiss``` index on your collection and that you generated the query embeddings as well.\n",
    "To do so, you need to \n",
    "1. encode the collection using a COLBERT (or JMPQ) model.\n",
    "2. encode the queries as above.\n",
    "3. build a faiss ivfpq index on the collection. \n",
    "\n",
    "For point 1 and 2, you can refer to the original github repos, [colbert](https://github.com/stanford-futuredata/ColBERT) and [jmpq](https://github.com/Suffoquer-fang/JMPQ). \n",
    "\n",
    "For point 3, you can use something like the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "500b733f-c4ec-44d4-8523-a59129c42403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nd = 128\\ncollection_path = \"\" # If the collection is too big, you may need to sample it. Make sure to keep about 10% of the original data\\ntraining_set = np.load(collection_path)\\n\\n\\nncentroids = # specify the number of centroids, somthing like 2**18\\nm = # specify the number of partitions \\nnbits = 8\\nquantizer = faiss.IndexFlatL2(d)\\n\\nindex = faiss.IndexIVFPQ(quantizer, d, ncentroids, m, nbits)\\nindex.train(training_set)\\n\\nsave_index_path = \"\"\\nfaiss.write_index(index, save_index_path)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "d = 128\n",
    "collection_path = \"\" # If the collection is too big, you may need to sample it. Make sure to keep about 10% of the original data\n",
    "training_set = np.load(collection_path)\n",
    "\n",
    "\n",
    "ncentroids = # specify the number of centroids, somthing like 2**18\n",
    "m = # specify the number of partitions \n",
    "nbits = 8\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "\n",
    "index = faiss.IndexIVFPQ(quantizer, d, ncentroids, m, nbits)\n",
    "index.train(training_set)\n",
    "\n",
    "save_index_path = \"\"\n",
    "faiss.write_index(index, save_index_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863e3c4-97dc-428c-ac1e-5914bbb3b4c4",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68872c29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Path to the faiss index\n",
    "\n",
    "index_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf714d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to the directory where the generated files will be saved\n",
    "\n",
    "dest_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32360fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir {dest_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff35ef",
   "metadata": {},
   "source": [
    "### Generate index decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc55cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_jmpq = faiss.read_index(index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac493993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "residuals = np.zeros([index_jmpq.ntotal, index_jmpq.pq.M], dtype= np.uint8)\n",
    "all_indices = np.zeros([index_jmpq.ntotal], dtype= np.uint64)\n",
    "centroids = index_jmpq.quantizer.reconstruct_n(0, index_jmpq.nlist)\n",
    "centroids_to_pids = [None] * centroids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb3b51a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doclensArray = np.load(\"./external/msmarco/doclens_msmarco.npy\")\n",
    "tot_embedding = ## total number of embeddings in your collection. Usually it can be obtained from index_jmpq.ntotal \n",
    "n_docs = len(doclensArray)\n",
    "emb2pid = np.zeros(tot_embedding, dtype = np.int64)\n",
    "offset = 0;\n",
    "for i in range(n_docs):\n",
    "    l = doclensArray[i]\n",
    "    emb2pid[offset: offset+l] = i\n",
    "    offset = offset + l\n",
    "doc_offsets = np.zeros(n_docs, dtype=np.int64)\n",
    "for i in range(1, n_docs):\n",
    "    doc_offsets[i] = doc_offsets[i-1] + doclensArray[i-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5470c191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 262144/262144 [01:21<00:00, 3217.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(index_jmpq.nlist)): \n",
    "    ids, codes = get_invlist(index_jmpq.invlists, i)\n",
    "    residuals[ids] = codes\n",
    "    all_indices[ids] = i\n",
    "    centroids_to_pids[i] = emb2pid[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "585fc5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 262144/262144 [03:38<00:00, 1197.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Write centroids to pids \n",
    "with open(os.path.join(dest_dir, \"centroids_to_pids.txt\"), \"w\") as file:\n",
    "    for centroids_list in tqdm(centroids_to_pids):\n",
    "        for x in centroids_list:\n",
    "            file.write(f\"{x} \")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed25f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write residuals\n",
    "np.save(os.path.join(dest_dir, \"residuals.npy\"), residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a30c2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write centroids\n",
    "np.save(os.path.join(dest_dir, \"centroids.npy\"), centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7344d1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write index_assignments\n",
    "np.save(os.path.join(dest_dir, \"index_assignment.npy\"), all_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0ef8835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write pq_centroids\n",
    "pq_centroids = faiss.vector_to_array(index_jmpq.pq.centroids)\n",
    "np.save(os.path.join(dest_dir, \"pq_centroids.npy\"), pq_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c6207-1329-41f8-9b00-b80c860a06d7",
   "metadata": {},
   "source": [
    "##### Query embeddings\n",
    "\n",
    "As a final step, you need to copy the query embeddings into ```dest_dir```, for example by using bash. \n",
    "\n",
    "- If you are running a simple PQ algorithm, then you just need to copy the query_embeddings as they are.\n",
    "- If you are running OPQ, you need to rotate the queries before copying. The rotation time is not included in the time measurements of EMVB as it is negligible compared to the search time. \n",
    "- If you are runnin JMPQ, you need to re-encode the queries as JMPQ fine-tunes also the query encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a58f3-383b-4f9e-a9d0-40920a93a88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
